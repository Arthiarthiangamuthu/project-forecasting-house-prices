# -*- coding: utf-8 -*-
"""Project-Phase2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uvyc_SnAsjee5Xm92LDhgQVOzCP2fxAf

Upload the Dataset
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
from google.colab import files

# Upload the file
uploaded = files.upload()

# Assuming the uploaded file is named 'Housing.csv.xlsx'
df = pd.read_excel('Housing.csv.xlsx')  # No need for sep

# Display the first few rows
df.head()

"""Data Exploration"""

# Display first few rows
df.head()

# Cell 2 - Display information about the DataFrame
print("Shape:", df.shape)
print("Columns:", df.columns.tolist())
df.info()
df.describe()

# Shape of the dataset
print("Shape:", df.shape)
# Column names
print("Columns:", df.columns.tolist())
# Data types and non-null values
df.info()
# Summary statistics for numeric features
df.describe()

"""Check for Missing Values and Duplicates"""

# Check for missing values
print(df.isnull().sum())
# Check for duplicates
print("Duplicate rows:", df.duplicated().sum())

"""Visualize a Few Features"""

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Distribution of house prices
sns.histplot(df['price'], kde=True)
plt.title('Distribution of House Prices')
plt.xlabel('Price')
plt.show()

# Relationship between number of bedrooms and price
sns.boxplot(x='bedrooms', y='price', data=df)
plt.title('Bedrooms vs House Price')
plt.xlabel('Number of Bedrooms')
plt.ylabel('Price')
plt.show()

"""Identify Target and Features"""

import pandas as pd # Make sure pandas is imported

# ... (Your other code)

target = 'hotwaterheating'

# Reload or recreate the DataFrame if necessary
# df = pd.read_csv('Housing.csv', sep=';')  # Assuming Housing.csv is your data file

features = df.columns.drop(target)
print("Features:", features)

"""One-Hot Encoding"""

df_encoded = pd.get_dummies('df', drop_first=True)

"""Feature Scaling"""

from sklearn.preprocessing import StandardScaler

# Check that 'price' exists in the DataFrame
# assert 'price' in df_encoded.columns, "'price' column not found in df_encoded"

# Scale the feature columns (excluding the target 'price')
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_encoded.drop('price', axis=1))

# Extract the target variable
y = df_encoded['price']

"""Train-Test Split"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""Model Building"""

# Train model
model = LinearRegression()
model.fit(X_train, y_train)
# Predict
y_pred = model.predict(X_test)

"""Evaluation"""

print("MSE:", mean_squared_error(y_test, y_pred))
print("R² Score:", r2_score(y_test, y_pred))

"""Make Predictions from New Input"""

# Sample input (replace values with any other valid values from the original dataset)
new_student = {
'school': 'GP', # 'GP' or 'MS'
'sex': 'F', # 'F' or 'M'
'age': 17, # Integer
'address': 'U', # 'U' or 'R'
'famsize': 'GT3', # 'LE3' or 'GT3'
'Pstatus': 'A', # 'A' or 'T'
'Medu': 4, # 0 to 4
'Fedu': 3, # 0 to 4
'Mjob': 'health', # 'teacher', 'health', etc.
'Fjob': 'services',
'reason': 'course',
'guardian': 'mother',
'traveltime': 2,
'studytime': 3,
'failures': 0,
'schoolsup': 'yes',
'famsup': 'no',
'paid': 'no',
'activities': 'yes',
'nursery': 'yes',
'higher': 'yes',
'internet': 'yes',
'romantic': 'no',
'famrel': 4,
'freetime': 3,
'goout': 3,
'Dalc': 1,
'Walc': 1,
'health': 4,
'absences': 2,
4/26/25, 12:08 PM sample project.ipynb - Colab
https://colab.research.google.com/drive/1LHSouQeD_tA9J58hn8Q1-yEM77VgZi3U#scrollTo=5BYaJj5jmg8c&printMode=true 9/14
'G1': 14,
'G2': 15
}

"""Convert to DataFrame and Encode"""

import numpy as np
# Convert to DataFrame
new_df = pd.DataFrame([new_student])
# Combine with original df to match columns
df_temp = pd.concat([df.drop('G3', axis=1), new_df], ignore_index=True)
# One-hot encode
df_temp_encoded = pd.get_dummies(df_temp, drop_first=True)
# Match the encoded feature order
df_temp_encoded = df_temp_encoded.reindex(columns=df_encoded.drop('G3', axis=1).columns, fill_value=0)
# Scale (if you used scaling)
new_input_scaled = scaler.transform(df_temp_encoded.tail(1))

"""Predict the Final Grade"""

predicted_grade = model.predict(new_input_scaled)
print("🎓 Predicted Final Grade (G3):", round(predicted_grade[0], 2))

"""Deployment-Building an Interactive App"""

!pip install gradio

"""Create a Prediction Function"""

import gradio as gr

"""Create the Gradio Interface"""

inputs = [
gr.Dropdown(['GP', 'MS'], label="School (GP=Gabriel Pereira, MS=Mousinho da Silveira)"),
gr.Dropdown(['M', 'F'], label="Gender (M=Male, F=Female)"),
gr.Number(label="Student Age"),
gr.Dropdown(['U', 'R'], label="Residence Area (U=Urban, R=Rural)"),
gr.Dropdown(['LE3', 'GT3'], label="Family Size (LE3=≤3, GT3=>3 members)"),
gr.Dropdown(['A', 'T'], label="Parent Cohabitation Status (A=Apart, T=Together)"),
gr.Number(label="Mother's Education Level (0-4)"),
gr.Number(label="Father's Education Level (0-4)"),
gr.Dropdown(['teacher', 'health', 'services', 'at_home', 'other'], label="Mother's Job"),
gr.Dropdown(['teacher', 'health', 'services', 'at_home', 'other'], label="Father's Job"),
gr.Dropdown(['home', 'reputation', 'course', 'other'], label="Reason for Choosing School"),
gr.Dropdown(['mother', 'father', 'other'], label="Guardian"),
gr.Number(label="Travel Time to School (1-4)"),
gr.Number(label="Weekly Study Time (1-4)"),
gr.Number(label="Past Class Failures (0-3)"),
gr.Dropdown(['yes', 'no'], label="Extra School Support"),
gr.Dropdown(['yes', 'no'], label="Family Support"),
gr.Dropdown(['yes', 'no'], label="Extra Paid Classes"),
gr.Dropdown(['yes', 'no'], label="Participates in Activities"),
gr.Dropdown(['yes', 'no'], label="Attended Nursery"),
gr.Dropdown(['yes', 'no'], label="Aspires Higher Education"),
gr.Dropdown(['yes', 'no'], label="Internet Access at Home"),
gr.Dropdown(['yes', 'no'], label="Currently in a Relationship"),
gr.Number(label="Family Relationship Quality (1-5)"),
gr.Number(label="Free Time After School (1-5)"),
gr.Number(label="Going Out Frequency (1-5)"),
gr.Number(label="Workday Alcohol Consumption (1-5)"),
4/26/25, 12:08 PM sample project.ipynb - Colab
https://colab.research.google.com/drive/1LHSouQeD_tA9J58hn8Q1-yEM77VgZi3U#scrollTo=5BYaJj5jmg8c&printMode=true 13/14
It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this
Colab notebook detected. To show errors in colab notebook, set debug=True in launch()
* Running on public URL: https://37518063c688a89403.gradio.live
This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces
🎓Student Performance Predictor
Enter academic and demographic info to predict the final grade (G3) of a student.
GP 0
School (GP=Gabriel Pereira, MS=Mousinho da Silveira) 🎯Predicted Final Grade (G3)
gr.Number(label="Weekend Alcohol Consumption (1-5)"),
gr.Number(label="Health Status (1=Very Bad to 5=Excellent)"),
gr.Number(label="Number of Absences"),
gr.Number(label="Grade in 1st Period (G1: 0-20)"),
gr.Number(label="Grade in 2nd Period (G2: 0-20)")
]

"""Upload the Dataset"""

from google.colab import files
uploaded = files.upload()

"""Load the Dataset"""

import pandas as pd

# Load the Excel file
df = pd.read_excel('/Housing.csv.xlsx')

# Preview the data
df.head()

"""Data Exploration"""

# Dataset shape
print("Shape of the dataset:", df.shape)

# Column names
print("Columns:", df.columns.tolist())

# Info about data types and missing values
df.info()

# Summary statistics
df.describe()

"""Data Cleaning"""

# Check for missing values
print("Missing values:\n", df.isnull().sum())

# Check for duplicates
print("Duplicate rows:", df.duplicated().sum())

"""Data Visualization (Modify column names as per your dataset)"""

import seaborn as sns
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt

# Example: Distribution of target column (e.g., price)
sns.histplot(df['price'], kde=True)
plt.title('Distribution of House Prices')
plt.xlabel('Price')
plt.show()

# Example: Boxplot of a feature vs price (adjust columns)
sns.boxplot(x='bedrooms', y='price', data=df)
plt.title('Bedrooms vs House Price')
plt.show()

# Example: Distribution of target column (e.g., price)
sns.histplot(df['price'], kde=True)
plt.title('Distribution of House Prices')
plt.xlabel('Price')
plt.show()

# Example: Boxplot of a feature vs price (adjust columns)
sns.boxplot(x='bedrooms', y='price', data=df)
plt.title('Bedrooms vs House Price')
plt.show()

"""Feature Selection and Target Definition"""

# Choose target and features
target = 'price'
features = df.columns.drop(target)

print("Target:", target)
print("Features:", features)

""" Encoding Categorical Variables"""

# Identify categorical columns
categorical_cols = df.select_dtypes(include='object').columns
print("Categorical columns:", categorical_cols.tolist())

# Apply one-hot encoding
df_encoded = pd.get_dummies(df, drop_first=True)

"""Feature Scaling"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_encoded.drop(target, axis=1))
y = df_encoded[target]

"""Train-Test Split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

""" Model Building (Linear Regression)"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

model = LinearRegression()
model.fit(X_train, y_train)

# Prediction
y_pred = model.predict(X_test)

"""Model Evaluation"""

print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R² Score:", r2_score(y_test, y_pred))

"""Predict from New Input"""

# Example: Replace with values from your actual dataset structure
new_data = {
    'area': 1500,
    'bedrooms': 3,
    'bathrooms': 2,
    'stories': 2,
    'mainroad': 'yes',
    'guestroom': 'no',
    'basement': 'yes',
    'hotwaterheating': 'no',
    'airconditioning': 'yes',
    'parking': 1,
    'prefarea': 'yes',
    'furnishingstatus': 'semi-furnished'
}

# Convert to DataFrame
new_df = pd.DataFrame([new_data])

# Combine with original for consistent encoding
temp_df = pd.concat([df.drop(columns=[target]), new_df], ignore_index=True)

# One-hot encode
temp_encoded = pd.get_dummies(temp_df, drop_first=True)

# Align with training features
temp_encoded = temp_encoded.reindex(columns=df_encoded.drop(target, axis=1).columns, fill_value=0)

# Scale
new_scaled = scaler.transform(temp_encoded.tail(1))

# Predict
prediction = model.predict(new_scaled)
print(f"🏠 Predicted House Price: ₹{prediction[0]:,.2f}")

""" Optional: Try Another Model (Random Forest)"""

from sklearn.ensemble import RandomForestRegressor

rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

rf_pred = rf_model.predict(X_test)

print("Random Forest MSE:", mean_squared_error(y_test, rf_pred))
print("Random Forest R²:", r2_score(y_test, rf_pred))

"""Deploy a Gradio App"""

!pip install gradio

import gradio as gr

def predict_house_price(area, bedrooms, bathrooms, stories, mainroad, guestroom,
                        basement, hotwaterheating, airconditioning, parking,
                        prefarea, furnishingstatus):

    input_dict = {
        'area': area,
        'bedrooms': bedrooms,
        'bathrooms': bathrooms,
        'stories': stories,
        'mainroad': mainroad,
        'guestroom': guestroom,
        'basement': basement,
        'hotwaterheating': hotwaterheating,
        'airconditioning': airconditioning,
        'parking': parking,
        'prefarea': prefarea,
        'furnishingstatus': furnishingstatus
    }

    input_df = pd.DataFrame([input_dict])
    combined_df = pd.concat([df.drop(columns=[target]), input_df], ignore_index=True)
    encoded_df = pd.get_dummies(combined_df, drop_first=True)
    encoded_df = encoded_df.reindex(columns=df_encoded.drop(target, axis=1).columns, fill_value=0)

    scaled_input = scaler.transform(encoded_df.tail(1))
    result = model.predict(scaled_input)[0]

    return f"₹{result:,.2f}"

# Define input fields
inputs = [
    gr.Number(label="Area (sq ft)"),
    gr.Number(label="Bedrooms"),
    gr.Number(label="Bathrooms"),
    gr.Number(label="Stories"),
    gr.Dropdown(['yes', 'no'], label="Main Road Access"),
    gr.Dropdown(['yes', 'no'], label="Guest Room"),
    gr.Dropdown(['yes', 'no'], label="Basement"),
    gr.Dropdown(['yes', 'no'], label="Hot Water Heating"),
    gr.Dropdown(['yes', 'no'], label="Air Conditioning"),
    gr.Number(label="Parking Spots"),
    gr.Dropdown(['yes', 'no'], label="Preferred Area"),
    gr.Dropdown(['furnished', 'semi-furnished', 'unfurnished'], label="Furnishing Status")
]

# Output field
output = gr.Text(label="Predicted House Price")

# Launch interface
gr.Interface(fn=predict_house_price, inputs=inputs, outputs=output,
             title="🏡 House Price Predictor",
             description="Enter housing details to estimate the price.").launch()

"""Save Model and Scaler (Optional for Reuse)"""

import joblib

joblib.dump(model, 'linear_model.pkl')
joblib.dump(scaler, 'scaler.pkl')